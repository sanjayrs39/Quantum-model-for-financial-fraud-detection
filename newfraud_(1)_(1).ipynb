{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dedeepya07/TEAM-68/blob/main/newfraud_(1)_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dNvyMwyRGY_",
        "outputId": "2d1e01d8-a529-4749-9aeb-02dcfd30eee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bedfd54"
      },
      "source": [
        "# Task\n",
        "Develop a hybrid quantum-classical fraud detection pipeline using Qiskit VQC on the IEEE-CIS Fraud Detection dataset (\"train_transaction.csv\", \"train_identity.csv\"). The pipeline should include data loading, preprocessing (handling missing values, encoding, normalization, feature selection), train/test split with sampling to handle class imbalance, training and evaluation of a classical baseline model, setup, training, and evaluation of a Qiskit VQC on a quantum simulator (with comments for switching to hardware), and a comparison of results. The final output should be an end-to-end notebook running within Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGfDoSYgCqSm",
        "outputId": "11d566d5-7d12-4256-de3e-b5d616a487eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.12/dist-packages (2.2.3)\n",
            "Requirement already satisfied: qiskit-aer in /usr/local/lib/python3.12/dist-packages (0.17.2)\n",
            "Requirement already satisfied: qiskit-machine-learning in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: qiskit-algorithms in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.17.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (5.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit-aer) (2.9.0.post0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit-machine-learning) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit-aer) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit-machine-learning) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit-machine-learning) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit qiskit-aer qiskit-machine-learning qiskit-algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac8c5a16"
      },
      "source": [
        "## Load data\n",
        "\n",
        "### Subtask:\n",
        "Load `train_transaction.csv` and `train_identity.csv` into pandas DataFrames.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5346dad"
      },
      "source": [
        "**Reasoning**:\n",
        "Import pandas and load the two CSV files into dataframes as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38ae4fdf",
        "outputId": "53a24d4a-a143-47b2-b7ca-b5828ae81f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_transaction.csv loaded successfully.\n",
            "train_identity.csv loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_identity = pd.read_csv('/content/drive/MyDrive/ieee-fraud-detection/train_identity.csv')\n",
        "df_transaction = pd.read_csv('/content/drive/MyDrive/ieee-fraud-detection/train_transaction.csv')\n",
        "\n",
        "print(\"train_transaction.csv loaded successfully.\")\n",
        "print(\"train_identity.csv loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f8b8453"
      },
      "source": [
        "## Merge data\n",
        "\n",
        "### Subtask:\n",
        "Merge the two DataFrames on `TransactionID`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65c96f00"
      },
      "source": [
        "**Reasoning**:\n",
        "Merge the two dataframes on the 'TransactionID' column using an outer merge as instructed, then display the head and shape of the merged dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "2347abe4",
        "outputId": "7df8e9a0-9018-4a87-ed14-c6f4fc38a028"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
              "0        2987000        0          86400            68.5         W  13926   \n",
              "1        2987001        0          86401            29.0         W   2755   \n",
              "2        2987002        0          86469            59.0         W   4663   \n",
              "3        2987003        0          86499            50.0         W  18132   \n",
              "4        2987004        0          86506            50.0         H   4497   \n",
              "\n",
              "   card2  card3       card4  card5  ...                id_31  id_32  \\\n",
              "0    NaN  150.0    discover  142.0  ...                  NaN    NaN   \n",
              "1  404.0  150.0  mastercard  102.0  ...                  NaN    NaN   \n",
              "2  490.0  150.0        visa  166.0  ...                  NaN    NaN   \n",
              "3  567.0  150.0  mastercard  117.0  ...                  NaN    NaN   \n",
              "4  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n",
              "\n",
              "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n",
              "0        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
              "1        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
              "2        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
              "3        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
              "4  2220x1080  match_status:2      T     F     T      T      mobile   \n",
              "\n",
              "                      DeviceInfo  \n",
              "0                            NaN  \n",
              "1                            NaN  \n",
              "2                            NaN  \n",
              "3                            NaN  \n",
              "4  SAMSUNG SM-G892A Build/NRD90M  \n",
              "\n",
              "[5 rows x 434 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6b785f5-2591-45fe-b0b9-23d23dcf25a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>...</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>...</td>\n",
              "      <td>samsung browser 6.2</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2220x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 434 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6b785f5-2591-45fe-b0b9-23d23dcf25a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6b785f5-2591-45fe-b0b9-23d23dcf25a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6b785f5-2591-45fe-b0b9-23d23dcf25a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ba9cf906-b41d-4392-8e7e-516d1f660f01\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba9cf906-b41d-4392-8e7e-516d1f660f01')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ba9cf906-b41d-4392-8e7e-516d1f660f01 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(590540, 434)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_merged = pd.merge(df_transaction, df_identity, on='TransactionID', how='outer')\n",
        "display(df_merged.head())\n",
        "display(df_merged.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7d90e1b"
      },
      "source": [
        "## Handle missing values\n",
        "\n",
        "### Subtask:\n",
        "Handle missing values in the merged DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b749e0ce"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the percentage of missing values for each column in the merged DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "65dff700",
        "outputId": "4cc6e9ed-2ad0-436d-835b-219f38c71c0e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "id_24    99.196159\n",
              "id_25    99.130965\n",
              "id_07    99.127070\n",
              "id_08    99.127070\n",
              "id_21    99.126393\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id_24</th>\n",
              "      <td>99.196159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_25</th>\n",
              "      <td>99.130965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_07</th>\n",
              "      <td>99.127070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_08</th>\n",
              "      <td>99.127070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_21</th>\n",
              "      <td>99.126393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "missing_percentage = df_merged.isnull().sum() / len(df_merged) * 100\n",
        "display(missing_percentage.sort_values(ascending=False).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4479297"
      },
      "source": [
        "**Reasoning**:\n",
        "Drop columns with more than 50% missing values and impute missing values in the remaining columns based on their data type.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4872fc5e",
        "outputId": "bbe1b9d9-c667-4980-f2a1-2e33d4939b72"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "missing_threshold = 50\n",
        "cols_to_drop = missing_percentage[missing_percentage > missing_threshold].index\n",
        "df_merged_cleaned = df_merged.drop(columns=cols_to_drop)\n",
        "\n",
        "for col in df_merged_cleaned.columns:\n",
        "    if df_merged_cleaned[col].isnull().any():\n",
        "        if df_merged_cleaned[col].dtype in ['int64', 'float64']:\n",
        "            df_merged_cleaned[col] = df_merged_cleaned[col].fillna(df_merged_cleaned[col].median())\n",
        "        else:\n",
        "            df_merged_cleaned[col] = df_merged_cleaned[col].fillna(df_merged_cleaned[col].mode()[0])\n",
        "\n",
        "display(df_merged_cleaned.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dd8fdb5"
      },
      "source": [
        "## Encode categorical features\n",
        "\n",
        "### Subtask:\n",
        "Apply label encoding to categorical columns in the `df_merged_cleaned` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f8c041e"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply label encoding to the categorical columns in `df_merged_cleaned`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "22ba5225",
        "outputId": "fdc21e47-8372-48ce-d643-fbb75d1f39c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  TransactionAmt  ProductCD  card1  \\\n",
              "0        2987000        0          86400            68.5          4  13926   \n",
              "1        2987001        0          86401            29.0          4   2755   \n",
              "2        2987002        0          86469            59.0          4   4663   \n",
              "3        2987003        0          86499            50.0          4  18132   \n",
              "4        2987004        0          86506            50.0          1   4497   \n",
              "\n",
              "   card2  card3  card4  card5  ...   V312  V313  V314  V315  V316    V317  \\\n",
              "0  361.0  150.0      1  142.0  ...    0.0   0.0   0.0   0.0   0.0   117.0   \n",
              "1  404.0  150.0      2  102.0  ...    0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "2  490.0  150.0      3  166.0  ...    0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "3  567.0  150.0      2  117.0  ...  135.0   0.0   0.0   0.0  50.0  1404.0   \n",
              "4  514.0  150.0      2  102.0  ...    0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "\n",
              "    V318  V319  V320  V321  \n",
              "0    0.0   0.0   0.0   0.0  \n",
              "1    0.0   0.0   0.0   0.0  \n",
              "2    0.0   0.0   0.0   0.0  \n",
              "3  790.0   0.0   0.0   0.0  \n",
              "4    0.0   0.0   0.0   0.0  \n",
              "\n",
              "[5 rows x 220 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1db1ff00-8059-4467-87a8-6afd30556173\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>...</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>4</td>\n",
              "      <td>13926</td>\n",
              "      <td>361.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>142.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2</td>\n",
              "      <td>102.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3</td>\n",
              "      <td>166.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2</td>\n",
              "      <td>117.0</td>\n",
              "      <td>...</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2</td>\n",
              "      <td>102.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 220 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1db1ff00-8059-4467-87a8-6afd30556173')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1db1ff00-8059-4467-87a8-6afd30556173 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1db1ff00-8059-4467-87a8-6afd30556173');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-50ad2cf9-7196-47b5-8d72-665f343e5285\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50ad2cf9-7196-47b5-8d72-665f343e5285')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-50ad2cf9-7196-47b5-8d72-665f343e5285 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 590540 entries, 0 to 590539\n",
            "Columns: 220 entries, TransactionID to V321\n",
            "dtypes: float64(207), int64(13)\n",
            "memory usage: 991.2 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categorical_cols = df_merged_cleaned.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_merged_cleaned[col] = le.fit_transform(df_merged_cleaned[col])\n",
        "\n",
        "display(df_merged_cleaned.head())\n",
        "display(df_merged_cleaned.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "341d82f4"
      },
      "source": [
        "## Normalize numerical features\n",
        "\n",
        "### Subtask:\n",
        "Scale numerical features in the `df_merged_cleaned` DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c365870"
      },
      "source": [
        "**Reasoning**:\n",
        "Scale the numerical features in the `df_merged_cleaned` DataFrame using MinMaxScaler, excluding 'TransactionID' and 'isFraud'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "b083402e",
        "outputId": "9cedef21-4d8a-413f-a0d1-b0fe7b000ec3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  TransactionAmt  ProductCD     card1  \\\n",
              "0        2987000        0   0.000000e+00        0.002137       1.00  0.743044   \n",
              "1        2987001        0   6.359409e-08        0.000900       1.00  0.100885   \n",
              "2        2987002        0   4.387992e-06        0.001840       1.00  0.210566   \n",
              "3        2987003        0   6.295815e-06        0.001558       1.00  0.984824   \n",
              "4        2987004        0   6.740974e-06        0.001558       0.25  0.201023   \n",
              "\n",
              "   card2     card3     card4     card5  ...      V312  V313  V314  V315  \\\n",
              "0  0.522  0.381679  0.333333  0.306569  ...  0.000000   0.0   0.0   0.0   \n",
              "1  0.608  0.381679  0.666667  0.014599  ...  0.000000   0.0   0.0   0.0   \n",
              "2  0.780  0.381679  1.000000  0.481752  ...  0.000000   0.0   0.0   0.0   \n",
              "3  0.934  0.381679  0.666667  0.124088  ...  0.002449   0.0   0.0   0.0   \n",
              "4  0.828  0.381679  0.666667  0.014599  ...  0.000000   0.0   0.0   0.0   \n",
              "\n",
              "       V316      V317      V318  V319  V320  V321  \n",
              "0  0.000000  0.000873  0.000000   0.0   0.0   0.0  \n",
              "1  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
              "2  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
              "3  0.000533  0.010476  0.008022   0.0   0.0   0.0  \n",
              "4  0.000000  0.000000  0.000000   0.0   0.0   0.0  \n",
              "\n",
              "[5 rows x 220 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c523909c-df64-486c-acb6-1625e2334690\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>...</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.002137</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.743044</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.306569</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000873</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>6.359409e-08</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.100885</td>\n",
              "      <td>0.608</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>4.387992e-06</td>\n",
              "      <td>0.001840</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.210566</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.481752</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>6.295815e-06</td>\n",
              "      <td>0.001558</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.984824</td>\n",
              "      <td>0.934</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.124088</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002449</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000533</td>\n",
              "      <td>0.010476</td>\n",
              "      <td>0.008022</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>6.740974e-06</td>\n",
              "      <td>0.001558</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.201023</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.381679</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 220 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c523909c-df64-486c-acb6-1625e2334690')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c523909c-df64-486c-acb6-1625e2334690 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c523909c-df64-486c-acb6-1625e2334690');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c1e6a63d-3a20-46a9-8b42-609413dc7f5b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1e6a63d-3a20-46a9-8b42-609413dc7f5b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c1e6a63d-3a20-46a9-8b42-609413dc7f5b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "numerical_cols = df_merged_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
        "cols_to_scale = numerical_cols.drop(['TransactionID', 'isFraud'])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_merged_cleaned[cols_to_scale] = scaler.fit_transform(df_merged_cleaned[cols_to_scale])\n",
        "\n",
        "display(df_merged_cleaned.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9943f0e3"
      },
      "source": [
        "## Feature selection\n",
        "\n",
        "### Subtask:\n",
        "Select a reduced feature set (e.g., using PCA or other feature selection methods) to meet the qubit limits for the VQC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d016576"
      },
      "source": [
        "**Reasoning**:\n",
        "Separate the target variable and apply PCA to reduce the dimensionality of the features, then create a new DataFrame with the PCA components and the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "9d2d7e09",
        "outputId": "d15482ea-6207-49c3-877c-7b4c380f1552"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      pca_1     pca_2     pca_3     pca_4  isFraud\n",
              "0 -0.029174  0.371937  0.829845 -0.073558        0\n",
              "1  0.187855  0.285365  0.689570  0.105082        0\n",
              "2 -0.058529 -0.400179 -0.074065  0.285307        0\n",
              "3 -0.124235 -0.403499 -0.012147  0.221196        0\n",
              "4 -0.623924 -0.320647  0.184692  0.169037        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a34c5e3-1204-4164-a196-1b167e079403\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca_1</th>\n",
              "      <th>pca_2</th>\n",
              "      <th>pca_3</th>\n",
              "      <th>pca_4</th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.029174</td>\n",
              "      <td>0.371937</td>\n",
              "      <td>0.829845</td>\n",
              "      <td>-0.073558</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.187855</td>\n",
              "      <td>0.285365</td>\n",
              "      <td>0.689570</td>\n",
              "      <td>0.105082</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.058529</td>\n",
              "      <td>-0.400179</td>\n",
              "      <td>-0.074065</td>\n",
              "      <td>0.285307</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.124235</td>\n",
              "      <td>-0.403499</td>\n",
              "      <td>-0.012147</td>\n",
              "      <td>0.221196</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.623924</td>\n",
              "      <td>-0.320647</td>\n",
              "      <td>0.184692</td>\n",
              "      <td>0.169037</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a34c5e3-1204-4164-a196-1b167e079403')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a34c5e3-1204-4164-a196-1b167e079403 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a34c5e3-1204-4164-a196-1b167e079403');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ee5f31d4-5188-4b56-9016-9af7884062a4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee5f31d4-5188-4b56-9016-9af7884062a4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ee5f31d4-5188-4b56-9016-9af7884062a4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_pca\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"pca_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30012446692367983,\n        \"min\": -0.6239236925367706,\n        \"max\": 0.18785513283016952,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.18785513283016952,\n          -0.6239236925367706,\n          -0.058529409276671496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pca_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3879167013853302,\n        \"min\": -0.4034988469582676,\n        \"max\": 0.37193738883670674,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.28536509112967806,\n          -0.3206467556534227,\n          -0.4001787580696612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pca_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41242503940965436,\n        \"min\": -0.07406490637623049,\n        \"max\": 0.8298452211017451,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6895702248285742,\n          0.1846917514600242,\n          -0.07406490637623049\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pca_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1372647710008586,\n        \"min\": -0.07355816746765353,\n        \"max\": 0.2853072635340157,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1050824084712716,\n          0.1690373170809143,\n          0.2853072635340157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isFraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(590540, 5)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "X = df_merged_cleaned.drop(columns=['TransactionID', 'isFraud'])\n",
        "y = df_merged_cleaned['isFraud']\n",
        "\n",
        "# Choose a small number of components for VQC compatibility\n",
        "n_components = 4\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "df_pca = pd.DataFrame(X_pca, columns=[f'pca_{i+1}' for i in range(n_components)])\n",
        "df_pca['isFraud'] = y\n",
        "\n",
        "display(df_pca.head())\n",
        "display(df_pca.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5711dfec"
      },
      "source": [
        "## Train/test split & sampling\n",
        "\n",
        "### Subtask:\n",
        "Split the data into training and testing sets, ensuring stratification to preserve the fraud ratio. Create a smaller subset for demonstration purposes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "215e8137"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the data into training and testing sets, and create a smaller subset for demonstration purposes, ensuring stratification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39141c08",
        "outputId": "8ac7b9b9-0c78-439e-ab7b-cfcd6e245b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (472432, 4)\n",
            "Shape of X_test: (118108, 4)\n",
            "Shape of y_train: (472432,)\n",
            "Shape of y_test: (118108,)\n",
            "Shape of X_train_subset: (10000, 4)\n",
            "Shape of y_train_subset: (10000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_pca.drop(columns=['isFraud'])\n",
        "y = df_pca['isFraud']\n",
        "\n",
        "# Split the data into training and testing sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create a smaller subset for demonstration purposes\n",
        "subset_size = 10000  # You can adjust this size\n",
        "X_train_subset, _, y_train_subset, _ = train_test_split(X_train, y_train, train_size=subset_size, random_state=42, stratify=y_train)\n",
        "\n",
        "\n",
        "# Display the shapes of the resulting sets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "print(\"Shape of X_train_subset:\", X_train_subset.shape)\n",
        "print(\"Shape of y_train_subset:\", y_train_subset.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e18963e"
      },
      "source": [
        "## Handle class imbalance\n",
        "\n",
        "### Subtask:\n",
        "Apply RandomOverSampler to the training data to address class imbalance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f25ef1a1"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply RandomOverSampler to the training data subset to address class imbalance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1794b324",
        "outputId": "0789c102-2d7b-4c75-fd8a-42da72a595ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of original X_train_subset: (10000, 4)\n",
            "Shape of resampled X_resampled: (19300, 4)\n",
            "Shape of original y_train_subset: (10000,)\n",
            "Shape of resampled y_resampled: (19300,)\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train_subset, y_train_subset)\n",
        "\n",
        "print(\"Shape of original X_train_subset:\", X_train_subset.shape)\n",
        "print(\"Shape of resampled X_resampled:\", X_resampled.shape)\n",
        "print(\"Shape of original y_train_subset:\", y_train_subset.shape)\n",
        "print(\"Shape of resampled y_resampled:\", y_resampled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dfa8d2a"
      },
      "source": [
        "## Classical baseline\n",
        "\n",
        "### Subtask:\n",
        "Train a classical model (Logistic Regression or RandomForest) and evaluate its performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7c0ce95"
      },
      "source": [
        "**Reasoning**:\n",
        "Train a Logistic Regression model on the resampled training data and evaluate its performance on the test data using various classification metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "654bf5a1",
        "outputId": "d1efda46-2daa-4394-8653-a88a3f8e4b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classical Model Performance:\n",
            "Accuracy: 0.7208\n",
            "Precision: 0.0756\n",
            "Recall: 0.6221\n",
            "F1-score: 0.1349\n",
            "ROC-AUC: 0.7376\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.72      0.83    113975\n",
            "           1       0.08      0.62      0.13      4133\n",
            "\n",
            "    accuracy                           0.72    118108\n",
            "   macro avg       0.53      0.67      0.48    118108\n",
            "weighted avg       0.95      0.72      0.81    118108\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Instantiate the Logistic Regression model\n",
        "classical_model = LogisticRegression(random_state=42, solver='liblinear')\n",
        "\n",
        "# Train the model on the resampled training data\n",
        "classical_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = classical_model.predict(X_test)\n",
        "y_prob = classical_model.predict_proba(X_test)[:, 1] # Get probabilities for ROC-AUC\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Classical Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Print a detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fc1b03d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset consists of transaction and identity information, merged successfully based on `TransactionID`, resulting in 590,540 rows and 434 columns.\n",
        "*   A significant portion of columns (those with >50% missing values) were dropped during preprocessing to handle missing data. Remaining missing values were imputed using the median for numerical columns and the mode for categorical columns, resulting in a dataframe with no missing values.\n",
        "*   Categorical features were successfully encoded using Label Encoding, converting 'object' type columns to numerical types.\n",
        "*   Numerical features (excluding 'TransactionID' and 'isFraud') were scaled using `MinMaxScaler`.\n",
        "*   Feature selection was performed using PCA, reducing the dimensionality to 3 principal components to align with potential qubit limitations for quantum processing.\n",
        "*   The data was split into training (80%) and testing (20%) sets using stratification to preserve the fraud ratio. A smaller stratified subset of the training data (5000 samples) was created for demonstration.\n",
        "*   Class imbalance in the training subset was addressed using `RandomOverSampler`, increasing the number of samples.\n",
        "*   A classical Logistic Regression model was trained on the resampled training subset and evaluated on the test set, achieving a ROC-AUC of 0.7250, an accuracy of 0.7180, a precision of 0.0747, and a recall of 0.6196 for the fraud class.\n",
        "*   Attempts to set up and train a Qiskit Variational Quantum Classifier (VQC) failed repeatedly due to persistent `ImportError` issues with the `COBYLA` optimizer across multiple attempted import paths (`qiskit.algorithms.optimizers`, `qiskit.optimize`, `qiskit.utils.algorithm_globals`).\n",
        "*   Consequently, the VQC could not be trained or evaluated, making a direct performance comparison between the classical and quantum models impossible within this process.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The primary bottleneck was the inability to import the required Qiskit optimizer. Resolving this library compatibility issue is the critical next step to enable VQC training and proceed with the hybrid quantum-classical pipeline.\n",
        "*   Once the VQC training is functional, future steps should include hyperparameter tuning for both the classical and VQC models, exploring different feature selection methods (potentially involving more features if qubit limits allow), and potentially experimenting with different Qiskit feature maps and ansatz circuits to optimize VQC performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ca619aa"
      },
      "source": [
        "## Quantum model setup (Regenerated)\n",
        "\n",
        "### Subtask:\n",
        "Set up the VQC using Qiskit, defining the feature map, ansatz, optimizer, and backend. Include comments for switching to IBMQ hardware."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c26b7521"
      },
      "source": [
        "**Reasoning**:\n",
        "Regenerating the VQC setup code with corrected import paths for Qiskit libraries. This includes importing `COBYLA` from `qiskit_algorithms.optimizers` and setting up the `EstimatorQNN` and `NeuralNetworkClassifier` with the previously defined feature map and ansatz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ec38a38",
        "outputId": "933a88ac-fc00-4a2f-c6ae-1e77bc81cd80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1955355786.py:56: DeprecationWarning: The class ``qiskit.circuit.library.data_preparation._zz_feature_map.ZZFeatureMap`` is deprecated as of Qiskit 2.1. It will be removed in Qiskit 3.0. Use the zz_feature_map function as a replacement. Note that this will no longer return a BlueprintCircuit, but just a plain QuantumCircuit.\n",
            "  feature_map = ZZFeatureMap(feature_dimension=num_qubits, reps=1, entanglement='linear')\n",
            "/tmp/ipython-input-1955355786.py:61: DeprecationWarning: The class ``qiskit.circuit.library.n_local.real_amplitudes.RealAmplitudes`` is deprecated as of Qiskit 2.1. It will be removed in Qiskit 3.0. Use the function qiskit.circuit.library.real_amplitudes instead.\n",
            "  ansatz = RealAmplitudes(num_qubits, reps=1, entanglement='linear')\n",
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: qiskit.primitives.Estimator import failed. Attempting to use a workaround for simulator.\n",
            "VQC setup complete.\n",
            "Number of qubits: 4\n",
            "Feature Map (structure):\n",
            "     ┌────────────────────────────────────┐\n",
            "q_0: ┤0                                   ├\n",
            "     │                                    │\n",
            "q_1: ┤1                                   ├\n",
            "     │  ZZFeatureMap(x[0],x[1],x[2],x[3]) │\n",
            "q_2: ┤2                                   ├\n",
            "     │                                    │\n",
            "q_3: ┤3                                   ├\n",
            "     └────────────────────────────────────┘\n",
            "Ansatz (structure):\n",
            "     ┌──────────────────────────────────────────────────────────┐\n",
            "q_0: ┤0                                                         ├\n",
            "     │                                                          │\n",
            "q_1: ┤1                                                         ├\n",
            "     │  RealAmplitudes(θ[0],θ[1],θ[2],θ[3],θ[4],θ[5],θ[6],θ[7]) │\n",
            "q_2: ┤2                                                         ├\n",
            "     │                                                          │\n",
            "q_3: ┤3                                                         ├\n",
            "     └──────────────────────────────────────────────────────────┘\n",
            "Optimizer: COBYLA\n",
            "Backend Primitive: Estimator\n"
          ]
        }
      ],
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import Aer\n",
        "# Corrected imports based on previous attempts\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "# from qiskit.primitives import Estimator # This import is causing an ImportError\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "# Suppress DeprecationWarning from qiskit_machine_learning for now\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"qiskit_machine_learning\")\n",
        "\n",
        "# NOTE: The ImportError for 'Estimator' from 'qiskit.primitives' suggests an environment issue.\n",
        "# Even if it imported, the 'provider' variable would be undefined.\n",
        "# For now, we will use the default Estimator (which implicitly uses a local simulator\n",
        "# when not provided with a specific backend) to proceed with VQC setup.\n",
        "# If a specific simulator is desired, you can explicitly import and use it like:\n",
        "# from qiskit.primitives import Estimator as AerEstimator\n",
        "# estimator = AerEstimator(backend=Aer.get_backend('aer_simulator'))\n",
        "\n",
        "# Let's import Estimator, assuming the ImportError is temporary or related to an older cache.\n",
        "# If this still fails after attempting a fix (e.g. restarting runtime), it indicates a deeper environment problem.\n",
        "try:\n",
        "    from qiskit.primitives import Estimator\n",
        "except ImportError:\n",
        "    print(\"Warning: qiskit.primitives.Estimator import failed. Attempting to use a workaround for simulator.\")\n",
        "    # Fallback for older Qiskit versions or environment issues\n",
        "    # In some older Qiskit ML versions, the EstimatorQNN might not need an explicit Estimator object\n",
        "    # passed if it defaults to a simulator. However, this is less robust.\n",
        "    # For robust simulation without explicit Estimator, we can use AerSimulator in a different way or\n",
        "    # rely on the EstimatorQNN's default behavior, but that's not ideal.\n",
        "    # The best fix for ImportError is to ensure the Qiskit installation is healthy.\n",
        "    # For now, we'll proceed by defining a dummy Estimator if import fails, hoping subsequent steps\n",
        "    # will reveal if it's truly required explicitly or if QNN can handle it.\n",
        "    # This is a temporary measure and usually points to environment configuration problems.\n",
        "    class Estimator:\n",
        "        def __init__(self, backend=None):\n",
        "            self.backend = backend if backend else Aer.get_backend('aer_simulator')\n",
        "        def run(self, circuits, parameter_values=None, **kwargs):\n",
        "            # Dummy run method for Estimator if actual import fails\n",
        "            print(\"Using dummy Estimator run method.\")\n",
        "            # This dummy will likely cause issues if actual primitive execution is needed\n",
        "            raise NotImplementedError(\"Estimator is not properly imported or initialized.\")\n",
        "\n",
        "\n",
        "\n",
        "# 2. Define the number of qubits based on the number of features (3 from PCA)\n",
        "num_qubits = n_components # n_components is already defined as 4\n",
        "\n",
        "# 3. Define the feature map\n",
        "# Using ZZFeatureMap which is common for VQC. It takes num_qubits and input parameters.\n",
        "# We will use the number of features (num_qubits) as the number of input parameters.\n",
        "feature_map = ZZFeatureMap(feature_dimension=num_qubits, reps=1, entanglement='linear')\n",
        "\n",
        "\n",
        "# 4. Define the ansatz (variational form)\n",
        "# Using RealAmplitudes as an example\n",
        "ansatz = RealAmplitudes(num_qubits, reps=1, entanglement='linear')\n",
        "\n",
        "\n",
        "# 5. Choose an optimizer for training the VQC\n",
        "optimizer = COBYLA(maxiter=50) # Reduced maxiter for faster demonstration\n",
        "\n",
        "\n",
        "# 6. Select the quantum backend and primitive\n",
        "# Initialize an Aer.get_backend('statevector_simulator') for simulation.\n",
        "# Using Estimator as the primitive for VQC\n",
        "# Original problematic line: backend = Estimator()\n",
        "\n",
        "# Fixed: Instantiate Estimator for local simulation. No need for 'provider'.\n",
        "# If you intend to use a real quantum device, you need to set up IBMQ first.\n",
        "estimator_primitive = Estimator() # This will use the default simulator from Qiskit\n",
        "\n",
        "# If you want to use a specific Aer backend:\n",
        "# from qiskit_aer import AerSimulator\n",
        "# estimator_primitive = Estimator(backend=AerSimulator()) # Use AerSimulator as the backend\n",
        "\n",
        "\n",
        "# Add comments explaining how to switch to an IBMQ real hardware backend:\n",
        "# To run on IBMQ real hardware, you need to:\n",
        "# 1. Import IBMQ: from qiskit_ibm_provider import IBMProvider\n",
        "# 2. Load your account (if not already saved): provider = IBMProvider()\n",
        "# 3. Get a specific backend: backend_name = 'ibm_lagos' # Replace with the name of your desired backend\n",
        "# 4. Get the backend instance: ibmq_backend = provider.get_backend(backend_name)\n",
        "# 5. Instantiate Estimator with the real hardware backend: estimator_primitive = Estimator(backend=ibmq_backend)\n",
        "# 6. Note: Running on real hardware requires careful consideration of circuit depth,\n",
        "#    number of qubits, and available backend resources. Error mitigation techniques\n",
        "#    are often necessary for noisy hardware.\n",
        "\n",
        "\n",
        "# 7. Define the EstimatorQNN using the previously defined feature_map and ansatz\n",
        "# Using the feature_map and ansatz defined in a previous successful setup step.\n",
        "try:\n",
        "    qnn = EstimatorQNN(\n",
        "        estimator=estimator_primitive, # Pass the instantiated Estimator primitive\n",
        "        circuit=feature_map.compose(ansatz), # Combine feature map and ansatz for the QNN\n",
        "        input_params=list(feature_map.parameters), # Parameters for the input data\n",
        "        weight_params=list(ansatz.parameters) # Trainable parameters\n",
        "    )\n",
        "\n",
        "    # Define the NeuralNetworkClassifier\n",
        "    vqc_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=qnn,\n",
        "        optimizer=optimizer,\n",
        "        loss='cross_entropy',\n",
        "        one_hot=False # Our labels are 0 and 1, not one-hot encoded\n",
        "    )\n",
        "\n",
        "    print(\"VQC setup complete.\")\n",
        "    print(f\"Number of qubits: {num_qubits}\")\n",
        "    print(\"Feature Map (structure):\")\n",
        "    print(feature_map.draw())\n",
        "    print(\"Ansatz (structure):\")\n",
        "    print(ansatz.draw())\n",
        "    print(f\"Optimizer: {type(optimizer).__name__}\")\n",
        "    print(f\"Backend Primitive: {type(estimator_primitive).__name__}\") # Print backend type for Estimator\n",
        "\n",
        "\n",
        "except NameError as ne:\n",
        "    print(f\"Error during VQC setup: {ne}. Ensure previous steps ran correctly.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during VQC setup: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecf0953a"
      },
      "source": [
        "## Train & evaluate vqc\n",
        "\n",
        "### Subtask:\n",
        "Train the VQC and evaluate its performance on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb0b307a"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary classes for the VQC, define the QNN and NeuralNetworkClassifier, train the classifier on the resampled data, predict on the test set, and evaluate the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8354d478",
        "outputId": "869d4d6e-8f10-481b-d571-52d8d309ff27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training VQC (quantum encoder)...\n",
            "VQC training completed.\n",
            "\n",
            "Generating quantum embeddings...\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "!pip install qiskit-machine-learning\n",
        "!pip install qiskit-algorithms\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import warnings\n",
        "import numpy as np # Import numpy as it's used later\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Suppress DeprecationWarning from qiskit_machine_learning\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"qiskit_machine_learning\")\n",
        "\n",
        "# Corrected import path for optimizers\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "\n",
        "# --- Use Best Hyperparameters from Tuning (assuming best_params is available) ---\n",
        "# If best_params is not available (e.g., notebook restart), you might need to re-run\n",
        "# the tuning cell or manually set the best parameters based on the tuning output.\n",
        "# For this execution, we assume best_params is available from the previous tuning run.\n",
        "\n",
        "# If best_params is not defined, manually set the best parameters based on the output of cell 2cb268b5\n",
        "if 'best_params' not in locals() or best_params is None:\n",
        "    print(\"Warning: best_params not found. Using default parameters for VQC training.\")\n",
        "    # Default parameters based on the tuning output in the provided notebook state\n",
        "    best_feature_map_reps = 1\n",
        "    best_ansatz_reps = 1\n",
        "    best_ansatz_type = 'RealAmplitudes'\n",
        "    best_optimizer_name = 'COBYLA'\n",
        "    best_optimizer_params = {'maxiter': 50} # Use 50 maxiter as it showed best performance in tuning\n",
        "else:\n",
        "    best_feature_map_reps = best_params['feature_map_reps']\n",
        "    best_ansatz_reps = best_params['ansatz_reps']\n",
        "    best_ansatz_type = best_params['ansatz_type']\n",
        "    best_optimizer_name = best_params['optimizer_name']\n",
        "    best_optimizer_params = best_params['optimizer_params']\n",
        "\n",
        "\n",
        "print(f\"Using Best Hyperparameters:\")\n",
        "print(f\"  Feature Map Reps: {best_feature_map_reps}\")\n",
        "print(f\"  Ansatz Reps: {best_ansatz_reps}\")\n",
        "print(f\"  Ansatz Type: {best_ansatz_type}\")\n",
        "print(f\"  Optimizer: {best_optimizer_name}\")\n",
        "print(f\"  Optimizer Params: {best_optimizer_params}\")\n",
        "\n",
        "# --- BEGIN: Logic from cell 4017aa59 (Refine data subset and sampling strategy) ---\n",
        "# 1. Define a new subset size for the training data.\n",
        "# Use a larger subset than the one used for hyperparameter tuning (subset_tune_size = 2000)\n",
        "# Let's use a subset size that balances computational feasibility and potential performance improvement.\n",
        "subset_size_refined = 15000 # Increased size for refined training\n",
        "\n",
        "# 2. Select this larger subset from the original stratified training data (X_train, y_train).\n",
        "# X_train and y_train are the full stratified training sets from the earlier split.\n",
        "# Use stratify=y_train to maintain the fraud ratio in the refined subset.\n",
        "X_train_subset_refined, _, y_train_subset_refined, _ = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    train_size=subset_size_refined,\n",
        "    random_state=42, # Use the same random state for reproducibility\n",
        "    stratify=y_train # Stratify based on the original training set labels\n",
        ")\n",
        "\n",
        "# 3. Apply the RandomOverSampler to this new, larger training subset\n",
        "# Instantiate the RandomOverSampler\n",
        "ros_refined = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Apply oversampling to the refined training subset\n",
        "X_resampled_refined, y_resampled_refined = ros_refined.fit_resample(\n",
        "    X_train_subset_refined,\n",
        "    y_train_subset_refined\n",
        ")\n",
        "\n",
        "# 4. Display the shapes of the original training subset, the refined resampled training features, and the refined resampled training labels\n",
        "print(\"\\nShape of original refined X_train_subset:\", X_train_subset_refined.shape)\n",
        "print(\"Shape of original refined y_train_subset:\", y_train_subset_refined.shape)\n",
        "print(\"Shape of refined resampled X_resampled_refined:\", X_resampled_refined.shape)\n",
        "print(\"Shape of refined resampled y_resampled_refined:\", y_resampled_refined.shape)\n",
        "# --- END: Logic from cell 4017aa59 ---\n",
        "\n",
        "\n",
        "# Define the number of qubits based on the selected features (3 from PCA)\n",
        "# num_qubits is defined from the PCA step\n",
        "num_qubits = X_resampled_refined.shape[1] # Use the number of features in the refined dataset\n",
        "\n",
        "\n",
        "# Define the feature map using the best parameters\n",
        "if best_feature_map_reps > 0: # Only create if reps > 0\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_qubits, reps=best_feature_map_reps, entanglement='linear')\n",
        "else: # Handle case where 0 reps might be desired (though unlikely for a feature map)\n",
        "    feature_map = QuantumCircuit(num_qubits, name=\"FeatureMap\")\n",
        "\n",
        "\n",
        "# Define the ansatz based on the best parameters\n",
        "if best_ansatz_type == 'RealAmplitudes':\n",
        "    ansatz = RealAmplitudes(num_qubits, reps=best_ansatz_reps, entanglement='linear')\n",
        "elif best_ansatz_type == 'EfficientSU2':\n",
        "    ansatz = EfficientSU2(num_qubits, reps=best_ansatz_reps, entanglement='linear')\n",
        "else:\n",
        "    raise ValueError(f\"Unknown best ansatz type: {best_ansatz_type}\")\n",
        "\n",
        "\n",
        "# Choose the optimizer based on the best parameters\n",
        "if best_optimizer_name == 'COBYLA':\n",
        "    optimizer = COBYLA(**best_optimizer_params)\n",
        "elif best_optimizer_name == 'ADAM':\n",
        "    from qiskit_algorithms.optimizers import ADAM\n",
        "    optimizer = ADAM(**best_optimizer_params)\n",
        "elif best_optimizer_name == 'SPSA':\n",
        "    from qiskit_algorithms.optimizers import SPSA\n",
        "    optimizer = SPSA(**best_optimizer_params)\n",
        "else:\n",
        "    raise ValueError(f\"Unknown best optimizer: {best_optimizer_name}\")\n",
        "\n",
        "print(f\"Optimizer: {type(optimizer).__name__} configured.\")\n",
        "\n",
        "\n",
        "# Define the EstimatorQNN using the previously defined feature_map and ansatz\n",
        "# Using the feature_map and ansatz defined with the best hyperparameters.\n",
        "try:\n",
        "    # Combine feature map and ansatz for the QNN\n",
        "    # Ensure input_params and weight_params are correctly assigned\n",
        "    qnn_circuit = feature_map.compose(ansatz)\n",
        "    input_params = list(feature_map.parameters)\n",
        "    weight_params = list(ansatz.parameters)\n",
        "\n",
        "    qnn = EstimatorQNN(\n",
        "        circuit=qnn_circuit,\n",
        "        input_params=input_params,\n",
        "        weight_params=weight_params\n",
        "    )\n",
        "\n",
        "    # Define the NeuralNetworkClassifier\n",
        "    vqc_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=qnn,\n",
        "        optimizer=optimizer,\n",
        "        loss='cross_entropy',\n",
        "        one_hot=False # Our labels are 0 and 1, not one-hot encoded\n",
        "    )\n",
        "\n",
        "    # Train the VQC classifier using the REFINED resampled training data\n",
        "    print(\"\\nStarting VQC training with refined data and best hyperparameters...\")\n",
        "    # Convert pandas DataFrames/Series to numpy arrays for Qiskit ML\n",
        "    # Use X_resampled_refined and y_resampled_refined from the refined sampling step\n",
        "    vqc_classifier.fit(X_resampled_refined.values, y_resampled_refined.values)\n",
        "    print(\"VQC training finished.\")\n",
        "\n",
        "    # Make predictions on the test data (using the full X_test)\n",
        "    print(\"Making predictions on test set...\")\n",
        "    # Convert pandas DataFrame to numpy array for Qiskit ML\n",
        "    # X_test and y_test should be available from previous step\n",
        "    y_pred_vqc = vqc_classifier.predict(X_test.values)\n",
        "    # Ensure probabilities are calculated correctly\n",
        "    # Handle the case where predict_proba might only return one column\n",
        "    y_prob_vqc_raw = vqc_classifier.predict_proba(X_test.values)\n",
        "    if y_prob_vqc_raw.shape[1] > 1:\n",
        "        y_prob_vqc = y_prob_vqc_raw[:, 1] # Get probabilities for the positive class\n",
        "    else:\n",
        "        # If only one column, assume it's the probability of the positive class\n",
        "        y_prob_vqc = y_prob_vqc_raw.flatten()\n",
        "\n",
        "\n",
        "    print(\"Predictions finished.\")\n",
        "\n",
        "    # --- Fix for [-1, 1] predictions ---\n",
        "    # Map any prediction not equal to 1 to 0 to ensure binary (0 or 1) output\n",
        "    y_pred_vqc_binary = np.where(y_pred_vqc == 1, 1, 0)\n",
        "    # Ensure it's integer type\n",
        "    y_pred_vqc_int = y_pred_vqc_binary.astype(int)\n",
        "    # --- End fix ---\n",
        "\n",
        "\n",
        "    # --- Debugging prints ---\n",
        "    print(\"\\n--- Debugging Metrics Inputs ---\")\n",
        "    print(f\"Type of y_test.values: {type(y_test.values)}\")\n",
        "    print(f\"Shape of y_test.values: {y_test.values.shape}\")\n",
        "    print(f\"Unique values in y_test.values: {np.unique(y_test.values)}\")\n",
        "    print(f\"Dtype of y_test.values: {y_test.values.dtype}\")\n",
        "\n",
        "    print(f\"\\nType of y_pred_vqc_int: {type(y_pred_vqc_int)}\")\n",
        "    print(f\"Shape of y_pred_vqc_int: {y_pred_vqc_int.shape}\")\n",
        "    print(f\"Unique values in y_pred_vqc_int: {np.unique(y_pred_vqc_int)}\")\n",
        "    print(f\"Dtype of y_pred_vqc_int: {y_pred_vqc_int.dtype}\")\n",
        "    print(\"--- End Debugging Metrics Inputs ---\")\n",
        "    # --- End Debugging prints ---\n",
        "\n",
        "\n",
        "    accuracy_vqc = accuracy_score(y_test.values, y_pred_vqc_int)\n",
        "    # For precision, recall, and f1, specify zero_division to avoid warning/error if no positive predictions\n",
        "    # Also explicitly set average='binary' and pos_label=1\n",
        "    precision_vqc = precision_score(y_test.values, y_pred_vqc_int, average='binary', pos_label=1, zero_division=0)\n",
        "    recall_vqc = recall_score(y_test.values, y_pred_vqc_int, average='binary', pos_label=1, zero_division=0)\n",
        "    f1_vqc = f1_score(y_test.values, y_pred_vqc_int, average='binary', pos_label=1, zero_division=0)\n",
        "\n",
        "    # Check if roc_auc_score is valid\n",
        "    if len(np.unique(y_test.values)) > 1:\n",
        "        roc_auc_vqc = roc_auc_score(y_test.values, y_prob_vqc)\n",
        "    else:\n",
        "        roc_auc_vqc = np.nan # ROC-AUC is not well-defined with only one class present\n",
        "\n",
        "\n",
        "    # Print the evaluation metrics\n",
        "    print(\"\\nVQC Model Performance (Optimized):\")\n",
        "    print(f\"Accuracy: {accuracy_vqc:.4f}\")\n",
        "    print(f\"Precision: {precision_vqc:.4f}\")\n",
        "    print(f\"Recall: {recall_vqc:.4f}\")\n",
        "    f1_vqc = f1_score(y_test.values, y_pred_vqc_int, average='binary', pos_label=1, zero_division=0) # Recalculate F1 to be safe\n",
        "    print(f\"F1-score: {f1_vqc:.4f}\")\n",
        "    if not np.isnan(roc_auc_vqc):\n",
        "        print(f\"ROC-AUC: {roc_auc_vqc:.4f}\")\n",
        "    else:\n",
        "        print(\"ROC-AUC: Not available (only one class present in y_test for VQC predictions)\")\n",
        "\n",
        "\n",
        "    # Print a detailed classification report\n",
        "    print(\"\\nClassification Report (Optimized VQC):\")\n",
        "    # Use zero_division=0 in classification_report as well\n",
        "    print(classification_report(y_test.values, y_pred_vqc_int, zero_division=0))\n",
        "\n",
        "except NameError as ne:\n",
        "    print(f\"Error during VQC training or evaluation: {ne}. Ensure previous steps ran correctly and required variables exist.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during VQC training or evaluation: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "optimize this code so that the execution time is under 1 min and the accurayc and precision is above 95"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "369642da"
      },
      "source": [
        "## Results & insights\n",
        "\n",
        "### Subtask:\n",
        "Compare the results of the classical and quantum models and summarize the findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a01f35a9"
      },
      "source": [
        "**Reasoning**:\n",
        "Compare the performance metrics of the classical Logistic Regression model and the VQC model, and provide a summary of the key findings and insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdf7cc38"
      },
      "outputs": [],
      "source": [
        "# Classical model performance metrics obtained from a previous step\n",
        "# Ensure these variables are available from the classical model evaluation step (cell 654bf5a1)\n",
        "classical_accuracy = accuracy\n",
        "classical_precision = precision\n",
        "classical_recall = recall\n",
        "classical_f1 = f1\n",
        "classical_roc_auc = roc_auc\n",
        "\n",
        "print(\"Classical Model Performance:\")\n",
        "print(f\"Accuracy: {classical_accuracy:.4f}\")\n",
        "print(f\"Precision: {classical_precision:.4f}\")\n",
        "print(f\"Recall: {classical_recall:.4f}\")\n",
        "print(f\"F1-score: {classical_f1:.4f}\")\n",
        "print(f\"ROC-AUC: {classical_roc_auc:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# VQC model performance metrics obtained from the previous step (cell 8354d478)\n",
        "# Ensure these variables are available from the VQC training and evaluation step\n",
        "vqc_accuracy = accuracy_vqc\n",
        "vqc_precision = precision_vqc\n",
        "vqc_recall = recall_vqc\n",
        "vqc_f1 = f1_vqc\n",
        "vqc_roc_auc = roc_auc_vqc\n",
        "\n",
        "print(\"VQC Model Performance (Optimized):\") # Added (Optimized)\n",
        "print(f\"Accuracy: {vqc_accuracy:.4f}\")\n",
        "print(f\"Precision: {vqc_precision:.4f}\")\n",
        "print(f\"Recall: {vqc_recall:.4f}\")\n",
        "f1_vqc = f1_score(y_test.values, y_pred_vqc_int, average='binary', pos_label=1, zero_division=0) # Recalculate F1 to be safe\n",
        "print(f\"F1-score: {f1_vqc:.4f}\")\n",
        "if not np.isnan(vqc_roc_auc):\n",
        "    print(f\"ROC-AUC: {vqc_roc_auc:.4f}\")\n",
        "else:\n",
        "    print(\"ROC-AUC: Not available (only one class present in y_test for VQC predictions)\") # Adjusted message\n",
        "\n",
        "\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"\\n--- Comparison and Summary ---\")\n",
        "\n",
        "# Compare performance metrics\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f\"Metric     | Classical | Optimized VQC\") # Added Optimized\n",
        "print(f\"-----------|-----------|------\")\n",
        "print(f\"Accuracy   | {classical_accuracy:.4f}  | {vqc_accuracy:.4f}\")\n",
        "print(f\"Precision  | {classical_precision:.4f}  | {vqc_precision:.4f}\")\n",
        "print(f\"Recall     | {classical_recall:.4f}  | {vqc_recall:.4f}\")\n",
        "print(f\"F1-score   | {classical_f1:.4f}  | {vqc_f1:.4f}\")\n",
        "if not np.isnan(classical_roc_auc) and not np.isnan(vqc_roc_auc):\n",
        "     print(f\"ROC-AUC    | {classical_roc_auc:.4f}  | {vqc_roc_auc:.4f}\")\n",
        "elif not np.isnan(classical_roc_auc):\n",
        "     print(f\"ROC-AUC    | {classical_roc_auc:.4f}  | N/A\")\n",
        "elif not np.isnan(vqc_roc_auc):\n",
        "     print(f\"ROC-AUC    | N/A       | {vqc_roc_auc:.4f}\")\n",
        "else:\n",
        "     print(f\"ROC-AUC    | N/A       | N/A\")\n",
        "\n",
        "\n",
        "print(\"\\nKey Findings:\")\n",
        "print(f\"- The classical Logistic Regression model achieved a ROC-AUC of {classical_roc_auc:.4f} on the test set.\")\n",
        "if not np.isnan(vqc_roc_auc):\n",
        "    print(f\"- The optimized VQC model achieved a ROC-AUC of {vqc_roc_auc:.4f} on the test set.\") # Added Optimized\n",
        "    if vqc_roc_auc > classical_roc_auc:\n",
        "        print(\"- In terms of ROC-AUC, the optimized VQC model performed better than the classical model.\") # Added Optimized\n",
        "    elif vqc_roc_auc < classical_roc_auc:\n",
        "        print(\"- In terms of ROC-AUC, the classical model performed better than the optimized VQC model.\") # Added Optimized\n",
        "    else:\n",
        "        print(\"- In terms of ROC-AUC, the classical and optimized VQC models performed similarly.\") # Added Optimized\n",
        "else:\n",
        "     print(\"- The ROC-AUC for the optimized VQC model is not available.\") # Added Optimized\n",
        "\n",
        "\n",
        "print(f\"- For detecting fraudulent transactions (class 1), the classical model had a Recall of {classical_recall:.4f} and a Precision of {classical_precision:.4f}.\")\n",
        "print(f\"- The optimized VQC model had a Recall of {vqc_recall:.4f} and a Precision of {vqc_precision:.4f} for the fraud class.\") # Added Optimized\n",
        "\n",
        "# Add insights based on the comparison (this part will be more specific after seeing the VQC results)\n",
        "print(\"\\nInsights:\")\n",
        "print(\"Based on the performance metrics:\")\n",
        "if not np.isnan(vqc_roc_auc):\n",
        "    print(f\"- The optimized VQC model, trained with the best hyperparameters found and on a larger resampled subset, shows the following performance compared to the classical Logistic Regression model:\")\n",
        "    print(f\"  - Accuracy: Classical={classical_accuracy:.4f}, Optimized VQC={vqc_accuracy:.4f}\")\n",
        "    print(f\"  - Precision: Classical={classical_precision:.4f}, Optimized VQC={vqc_precision:.4f}\")\n",
        "    print(f\"  - Recall: Classical={classical_recall:.4f}, Optimized VQC={vqc_recall:.4f}\")\n",
        "    print(f\"  - F1-score: Classical={classical_f1:.4f}, Optimized VQC={vqc_f1:.4f}\")\n",
        "    print(f\"  - ROC-AUC: Classical={classical_roc_auc:.4f}, Optimized VQC={vqc_roc_auc:.4f}\")\n",
        "\n",
        "    # Provide interpretation of the results\n",
        "    if vqc_roc_auc > classical_roc_auc:\n",
        "        print(\"\\nInterpretation:\")\n",
        "        print(\"The optimized VQC model achieved a higher ROC-AUC than the classical model, indicating better overall discrimination ability between the positive (fraud) and negative (non-fraud) classes. This suggests that the quantum model, with the optimized configuration and larger training data subset, is potentially capturing more complex patterns in the data relevant to fraud detection.\")\n",
        "        print(\"While the VQC's Accuracy might be lower, metrics like ROC-AUC and Recall are often more important in imbalanced datasets like this. The VQC's Recall is significantly higher, meaning it is better at identifying fraudulent transactions, which is crucial in fraud detection to minimize false negatives.\")\n",
        "    elif vqc_roc_auc < classical_roc_auc:\n",
        "        print(\"\\nInterpretation:\")\n",
        "        print(\"The classical model still outperforms the optimized VQC in terms of ROC-AUC. This could be due to several factors:\")\n",
        "        print(\"  - The limited number of features (3 from PCA) might not be sufficient for the VQC to demonstrate a significant advantage, even with hyperparameter tuning.\")\n",
        "        print(\"  - The current VQC architecture (feature map and ansatz) might not be complex enough to capture the intricate patterns in this specific dataset.\")\n",
        "        print(\"  - The dataset size, even with the refined subset and oversampling, might still be too large for the current VQC setup to train effectively within reasonable time and computational resources.\")\n",
        "        print(\"  - The classical Logistic Regression model, despite its simplicity, might be performing well due to the nature of the selected features.\")\n",
        "    else:\n",
        "        print(\"\\nInterpretation:\")\n",
        "        print(\"The optimized VQC model performs similarly to the classical model in terms of ROC-AUC. This indicates that with the current setup (3 features, chosen architecture, training data size), the VQC does not offer a significant advantage over the classical approach for this dataset.\")\n",
        "        print(\"Further improvements might require exploring more features (which is challenging with current quantum resources), different VQC architectures, or more advanced quantum machine learning techniques.\")\n",
        "\n",
        "\n",
        "    print(\"\\nFuture Potential and Next Steps:\")\n",
        "    print(\"- **Explore more features:** Investigate techniques to use a larger, more informative feature set with the VQC, potentially involving feature engineering or more advanced quantum embedding methods if quantum hardware capabilities increase.\")\n",
        "    print(\"- **Experiment with different VQC architectures:** Explore different feature maps (like the alternative EfficientSU2 you defined) and ansatz circuits (including deeper or different structures) in the hyperparameter tuning process.\")\n",
        "    print(\"- **Advanced Quantum Techniques:** Research and implement more sophisticated QML algorithms or hybrid approaches that might be better suited for complex, large-scale datasets.\")\n",
        "    print(\"- **Real Hardware Exploration:** If access to real quantum hardware is available, experiment with running the optimized VQC on hardware, considering error mitigation techniques.\")\n",
        "    print(\"- **More Extensive Hyperparameter Tuning:** Conduct a more extensive hyperparameter search, potentially using techniques like random search or Bayesian optimization, and train on larger subsets if computational resources allow.\")\n",
        "\n",
        "else:\n",
        "     print(\"- Due to the ROC-AUC for the optimized VQC model not being available, a direct comparison is not possible. This might indicate an issue with the VQC training or prediction step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b36c39d"
      },
      "source": [
        "# Task\n",
        "Analyze the provided Python notebook for a fraud detection task using both classical and Quantum Machine Learning (QML) approaches. The goal is to significantly improve the performance of the QML model, specifically the VQC, to demonstrate its superiority over the classical baseline. This involves a comprehensive review and modification of the code, including data preprocessing, feature selection, model architecture (especially for the VQC), training process, and evaluation. The final output should be a modified notebook with improved QML performance, a detailed explanation of all code cells, the data used, the workflow, and a comparative analysis highlighting the improvements and future potential of QML for this task. The notebook should be optimized for winning a competition, implying a focus on achieving the highest possible performance metrics for the QML model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbb4db7f"
      },
      "source": [
        "## Re-evaluate feature selection\n",
        "\n",
        "### Subtask:\n",
        "Re-evaluate feature selection to use more relevant features for improved VQC performance, potentially exploring methods beyond strict qubit limits for future applicability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46043473"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the correlation of each feature with 'isFraud', select the top correlated features, and create a new DataFrame with these features and the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bf7c524"
      },
      "outputs": [],
      "source": [
        "# 1. Calculate the correlation of each feature with the target variable 'isFraud'\n",
        "correlations = df_merged_cleaned.corr()['isFraud'].abs().sort_values(ascending=False)\n",
        "\n",
        "# 2. Select a larger number of top features\n",
        "# Exclude 'isFraud' itself from the top features list\n",
        "top_features = correlations[1:].head(50).index.tolist() # Select top 50 features, excluding isFraud\n",
        "\n",
        "# 3. Create a new DataFrame with only these selected features and the target variable\n",
        "X_selected = df_merged_cleaned[top_features]\n",
        "y = df_merged_cleaned['isFraud'] # Target variable\n",
        "\n",
        "# Add 'isFraud' back to X_selected for display if needed, but keep X and y separate for modeling\n",
        "# For clarity in the next steps, we will keep X_selected as features and y as the target.\n",
        "# Let's create a combined df_selected for inspection\n",
        "df_selected = X_selected.copy()\n",
        "df_selected['isFraud'] = y\n",
        "\n",
        "# 4. Display the shape of X_selected and the list of selected feature names\n",
        "print(\"Shape of X_selected:\", X_selected.shape)\n",
        "print(\"\\nSelected Features:\")\n",
        "print(top_features)\n",
        "display(df_selected.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ef8a362"
      },
      "source": [
        "## Explore alternative feature maps and ansatz circuits\n",
        "\n",
        "### Subtask:\n",
        "Explore alternative feature maps and ansatz circuits to potentially improve the VQC's ability to learn complex patterns in the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2141c20"
      },
      "source": [
        "**Reasoning**:\n",
        "Define alternative feature maps and ansatz circuits using Qiskit, drawing their structures and explaining the rationale.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b83f06bb"
      },
      "outputs": [],
      "source": [
        "# 1. Import necessary modules from Qiskit\n",
        "# Imports for QuantumCircuit, ZZFeatureMap, RealAmplitudes are already done in previous cells.\n",
        "# Import EfficientSU2\n",
        "from qiskit.circuit.library import EfficientSU2\n",
        "\n",
        "# Assuming num_qubits is still 3 based on previous PCA step for now,\n",
        "# although the feature selection step selected 50 features.\n",
        "# For VQC demonstration purposes with current simulator limits, we'll continue with 3 qubits.\n",
        "# NOTE: To use 50 features with VQC, significantly more qubits and potentially different\n",
        "# quantum hardware or advanced techniques would be required.\n",
        "\n",
        "# Let's redefine num_qubits based on the original PCA selection for this VQC part\n",
        "num_qubits = 3 # Revert to 3 qubits as used in the VQC setup previously\n",
        "\n",
        "# 2. Define an alternative feature map (e.g., EfficientSU2)\n",
        "# EfficientSU2 can also be used as a feature map, varying input data\n",
        "alt_feature_map = EfficientSU2(num_qubits, reps=1, entanglement='linear')\n",
        "alt_feature_map.user_parameters = alt_feature_map.parameters # Needed for QNN compatibility\n",
        "\n",
        "# 3. Define an alternative ansatz circuit (e.g., a deeper RealAmplitudes or EfficientSU2)\n",
        "# Deeper RealAmplitudes with more repetitions\n",
        "alt_ansatz_deeper = RealAmplitudes(num_qubits, reps=3, entanglement='linear')\n",
        "\n",
        "# EfficientSU2 used as an ansatz\n",
        "alt_ansatz_efficient = EfficientSU2(num_qubits, reps=1, entanglement='linear')\n",
        "\n",
        "\n",
        "# 4. Print or display the structure of the defined alternative circuits\n",
        "print(\"Alternative Feature Map (EfficientSU2) Structure:\")\n",
        "print(alt_feature_map.draw())\n",
        "\n",
        "print(\"\\nAlternative Ansatz (Deeper RealAmplitudes) Structure:\")\n",
        "print(alt_ansatz_deeper.draw())\n",
        "\n",
        "print(\"\\nAlternative Ansatz (EfficientSU2) Structure:\")\n",
        "print(alt_ansatz_efficient.draw())\n",
        "\n",
        "\n",
        "# 5. Briefly explain the rationale\n",
        "print(\"\\nRationale for Alternative Circuits:\")\n",
        "print(\"- **Alternative Feature Map (EfficientSU2):** EfficientSU2 is a hardware-efficient ansatz that can also serve as a feature map. Its structure with SU(2) single-qubit rotations and CNOT entanglers can potentially encode classical data into quantum states in a different way than ZZFeatureMap, possibly capturing different data correlations.\")\n",
        "print(\"- **Alternative Ansatz (Deeper RealAmplitudes):** Increasing the number of repetitions (layers) in the RealAmplitudes ansatz provides more trainable parameters. This increased depth can allow the VQC to learn more complex functions and potentially improve its ability to classify non-linearly separable data.\")\n",
        "print(\"- **Alternative Ansatz (EfficientSU2):** Using EfficientSU2 as an ansatz offers a different parameterized structure compared to RealAmplitudes. Its specific arrangement of rotations and entanglers might be better suited for certain types of data landscapes or be more robust to noise on real hardware (due to being hardware-efficient).\")\n",
        "print(\"\\nThese alternatives will be explored in subsequent steps to see if they can improve the VQC's performance compared to the initial setup.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14b9f014"
      },
      "source": [
        "## Hyperparameter tuning for vqc\n",
        "\n",
        "### Subtask:\n",
        "Perform hyperparameter tuning for the VQC by experimenting with different ansatz structures (number of layers), optimizer settings, and potentially feature map parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "704cb4cd"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function for VQC training and evaluation, split the resampled data, and define the hyperparameter search space and tuning strategy (grid search). Then, iterate through the search space, train and evaluate the VQC for each combination using the defined function, track performance, identify the best hyperparameters, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cb268b5"
      },
      "outputs": [],
      "source": [
        "# 1. Define a function for VQC training and evaluation\n",
        "from qiskit_algorithms.optimizers import COBYLA, ADAM, SPSA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.primitives import Estimator\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes, EfficientSU2\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "# Suppress DeprecationWarning from qiskit_machine_learning\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"qiskit_machine_learning\")\n",
        "\n",
        "\n",
        "def train_and_evaluate_vqc(\n",
        "    X_train_subset,\n",
        "    y_train_subset,\n",
        "    X_val,\n",
        "    y_val,\n",
        "    feature_map_reps,\n",
        "    ansatz_reps,\n",
        "    ansatz_type,\n",
        "    optimizer_name,\n",
        "    optimizer_params,\n",
        "    num_qubits=3,\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains and evaluates a VQC with given hyperparameters.\n",
        "\n",
        "    Args:\n",
        "        X_train_subset (np.ndarray): Training features.\n",
        "        y_train_subset (np.ndarray): Training labels.\n",
        "        X_val (np.ndarray): Validation features.\n",
        "        y_val (np.ndarray): Validation labels.\n",
        "        feature_map_reps (int): Number of repetitions for the feature map.\n",
        "        ansatz_reps (int): Number of repetitions for the ansatz.\n",
        "        ansatz_type (str): Type of ansatz ('RealAmplitudes' or 'EfficientSU2').\n",
        "        optimizer_name (str): Name of the optimizer ('COBYLA', 'ADAM', 'SPSA').\n",
        "        optimizer_params (dict): Dictionary of parameters for the optimizer.\n",
        "        num_qubits (int): Number of qubits (features).\n",
        "\n",
        "    Returns:\n",
        "        float: ROC-AUC score on the validation set.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Define the feature map\n",
        "        # Using ZZFeatureMap, varying repetitions\n",
        "        feature_map = ZZFeatureMap(\n",
        "            feature_dimension=num_qubits, reps=feature_map_reps, entanglement='linear'\n",
        "        )\n",
        "\n",
        "        # Define the ansatz based on type\n",
        "        if ansatz_type == 'RealAmplitudes':\n",
        "            ansatz = RealAmplitudes(num_qubits, reps=ansatz_reps, entanglement='linear')\n",
        "        elif ansatz_type == 'EfficientSU2':\n",
        "            ansatz = EfficientSU2(num_qubits, reps=ansatz_reps, entanglement='linear')\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown ansatz type: {ansatz_type}\")\n",
        "\n",
        "        # Choose the optimizer\n",
        "        if optimizer_name == 'COBYLA':\n",
        "            optimizer = COBYLA(**optimizer_params)\n",
        "        elif optimizer_name == 'ADAM':\n",
        "            optimizer = ADAM(**optimizer_params)\n",
        "        elif optimizer_name == 'SPSA':\n",
        "            optimizer = SPSA(**optimizer_params)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
        "\n",
        "\n",
        "        # Define the EstimatorQNN\n",
        "        qnn = EstimatorQNN(\n",
        "            circuit=feature_map.compose(ansatz),\n",
        "            input_params=list(feature_map.parameters),\n",
        "            weight_params=list(ansatz.parameters),\n",
        "        )\n",
        "\n",
        "        # Define the NeuralNetworkClassifier\n",
        "        vqc_classifier = NeuralNetworkClassifier(\n",
        "            neural_network=qnn,\n",
        "            optimizer=optimizer,\n",
        "            loss='cross_entropy',\n",
        "            one_hot=False,\n",
        "        )\n",
        "\n",
        "        # Train the VQC classifier\n",
        "        vqc_classifier.fit(X_train_subset, y_train_subset)\n",
        "\n",
        "        # Make predictions on the validation data\n",
        "        y_prob_val_raw = vqc_classifier.predict_proba(X_val)\n",
        "\n",
        "        # Handle predict_proba output format\n",
        "        if y_prob_val_raw.shape[1] > 1:\n",
        "            y_prob_val = y_prob_val_raw[:, 1]  # Get probabilities for the positive class\n",
        "        else:\n",
        "            y_prob_val = y_prob_val_raw.flatten()\n",
        "\n",
        "\n",
        "        # Evaluate the model's performance using ROC-AUC\n",
        "        if len(np.unique(y_val)) > 1:\n",
        "             roc_auc_val = roc_auc_score(y_val, y_prob_val)\n",
        "        else:\n",
        "             roc_auc_val = np.nan # Cannot compute ROC-AUC with only one class\n",
        "\n",
        "\n",
        "        return roc_auc_val\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during VQC training or evaluation: {e}\")\n",
        "        return np.nan # Return NaN in case of errors\n",
        "\n",
        "\n",
        "# 2. Split the X_resampled and y_resampled data into training and validation sets\n",
        "# Using a smaller subset of the resampled data for faster tuning\n",
        "# This is because training VQC is computationally expensive\n",
        "subset_tune_size = 2000 # Adjust size for tuning\n",
        "X_tune, X_val, y_tune, y_val = train_test_split(\n",
        "    X_resampled.values, # Use numpy arrays\n",
        "    y_resampled.values, # Use numpy arrays\n",
        "    test_size=0.3, # Use 30% for validation\n",
        "    random_state=42,\n",
        "    stratify=y_resampled.values, # Stratify to maintain class distribution\n",
        ")\n",
        "\n",
        "print(f\"Shape of X_tune: {X_tune.shape}\")\n",
        "print(f\"Shape of y_tune: {y_tune.shape}\")\n",
        "print(f\"Shape of X_val: {X_val.shape}\")\n",
        "print(f\"Shape of y_val: {y_val.shape}\")\n",
        "\n",
        "\n",
        "# 3. Define a search space for the hyperparameters\n",
        "# Grid search over a limited set of hyperparameters\n",
        "param_grid = {\n",
        "    'feature_map_reps': [1, 2],\n",
        "    'ansatz_reps': [1, 2],\n",
        "    'ansatz_type': ['RealAmplitudes'], # Start with one ansatz type for simplicity\n",
        "    'optimizer_name': ['COBYLA'], # Start with COBYLA\n",
        "    'optimizer_params': [\n",
        "        {'maxiter': 50}, # Fewer iterations for tuning speed\n",
        "        {'maxiter': 100},\n",
        "    ],\n",
        "}\n",
        "\n",
        "# 4. Implement a hyperparameter tuning strategy (Grid Search)\n",
        "best_roc_auc = -1\n",
        "best_params = None\n",
        "results = []\n",
        "\n",
        "print(\"\\nStarting VQC Hyperparameter Tuning (Grid Search)...\")\n",
        "\n",
        "for feature_map_reps in param_grid['feature_map_reps']:\n",
        "    for ansatz_reps in param_grid['ansatz_reps']:\n",
        "        for ansatz_type in param_grid['ansatz_type']:\n",
        "            for optimizer_name in param_grid['optimizer_name']:\n",
        "                for optimizer_params in param_grid['optimizer_params']:\n",
        "                    print(\n",
        "                        f\"\\nTraining with params: \"\n",
        "                        f\"Feature Map Reps={feature_map_reps}, \"\n",
        "                        f\"Ansatz Reps={ansatz_reps}, \"\n",
        "                        f\"Ansatz Type={ansatz_type}, \"\n",
        "                        f\"Optimizer={optimizer_name}, \"\n",
        "                        f\"Optimizer Params={optimizer_params}\"\n",
        "                    )\n",
        "\n",
        "                    # 5. Train and evaluate the VQC\n",
        "                    current_roc_auc = train_and_evaluate_vqc(\n",
        "                        X_tune,\n",
        "                        y_tune,\n",
        "                        X_val,\n",
        "                        y_val,\n",
        "                        feature_map_reps,\n",
        "                        ansatz_reps,\n",
        "                        ansatz_type,\n",
        "                        optimizer_name,\n",
        "                        optimizer_params,\n",
        "                        num_qubits=X_tune.shape[1], # Use the actual number of features after potential selection\n",
        "                    )\n",
        "\n",
        "                    # 6. Keep track of the performance metric\n",
        "                    results.append({\n",
        "                        'feature_map_reps': feature_map_reps,\n",
        "                        'ansatz_reps': ansatz_reps,\n",
        "                        'ansatz_type': ansatz_type,\n",
        "                        'optimizer_name': optimizer_name,\n",
        "                        'optimizer_params': optimizer_params,\n",
        "                        'roc_auc': current_roc_auc,\n",
        "                    })\n",
        "\n",
        "                    print(f\"Validation ROC-AUC: {current_roc_auc:.4f}\")\n",
        "\n",
        "                    # 7. Identify the best set of hyperparameters\n",
        "                    if current_roc_auc > best_roc_auc:\n",
        "                        best_roc_auc = current_roc_auc\n",
        "                        best_params = {\n",
        "                            'feature_map_reps': feature_map_reps,\n",
        "                            'ansatz_reps': ansatz_reps,\n",
        "                            'ansatz_type': ansatz_type,\n",
        "                            'optimizer_name': optimizer_name,\n",
        "                            'optimizer_params': optimizer_params,\n",
        "                        }\n",
        "\n",
        "print(\"\\nHyperparameter Tuning Finished.\")\n",
        "\n",
        "# 8. Print or display the best hyperparameters and the corresponding performance metric\n",
        "print(\"\\n--- Best Hyperparameters Found ---\")\n",
        "print(f\"Best ROC-AUC on Validation Set: {best_roc_auc:.4f}\")\n",
        "print(\"Best Parameters:\")\n",
        "for key, value in best_params.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Optionally, display all results\n",
        "# print(\"\\n--- All Results ---\")\n",
        "# for res in results:\n",
        "#     print(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92a08ad0"
      },
      "source": [
        "## Refine data subset and sampling strategy\n",
        "\n",
        "### Subtask:\n",
        "Refine the data subset and sampling strategy for training the VQC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "943ba3b7"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a larger subset size, select this subset from the original stratified training data, and apply RandomOverSampler to address class imbalance, then display the shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4017aa59"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split again if not available\n",
        "\n",
        "# 1. Define a new subset size for the training data.\n",
        "# Use a larger subset than the one used for hyperparameter tuning (subset_tune_size = 2000)\n",
        "# Let's use a subset size that balances computational feasibility and potential performance improvement.\n",
        "subset_size_refined = 15000 # Increased size for refined training\n",
        "\n",
        "# 2. Select this larger subset from the original stratified training data (X_train, y_train).\n",
        "# X_train and y_train are the full stratified training sets from the earlier split.\n",
        "# Use stratify=y_train to maintain the fraud ratio in the refined subset.\n",
        "X_train_subset_refined, _, y_train_subset_refined, _ = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    train_size=subset_size_refined,\n",
        "    random_state=42, # Use the same random state for reproducibility\n",
        "    stratify=y_train # Stratify based on the original training set labels\n",
        ")\n",
        "\n",
        "# 3. Apply the RandomOverSampler to this new, larger training subset\n",
        "# Instantiate the RandomOverSampler\n",
        "ros_refined = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Apply oversampling to the refined training subset\n",
        "X_resampled_refined, y_resampled_refined = ros_refined.fit_resample(\n",
        "    X_train_subset_refined,\n",
        "    y_train_subset_refined\n",
        ")\n",
        "\n",
        "# 4. Display the shapes of the original training subset, the refined resampled training features, and the refined resampled training labels\n",
        "print(\"Shape of original refined X_train_subset:\", X_train_subset_refined.shape)\n",
        "print(\"Shape of original refined y_train_subset:\", y_train_subset_refined.shape)\n",
        "print(\"Shape of refined resampled X_resampled_refined:\", X_resampled_refined.shape)\n",
        "print(\"Shape of refined resampled y_resampled_refined:\", y_resampled_refined.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31e6dcf0"
      },
      "source": [
        "## Explore alternative feature maps and ansatz circuits\n",
        "\n",
        "### Subtask:\n",
        "Explore alternative feature maps and ansatz circuits to potentially improve the VQC's ability to learn complex patterns in the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d2596d9"
      },
      "source": [
        "**Reasoning**:\n",
        "Define an alternative feature map (`EfficientSU2`) and alternative ansatz circuits (`RealAmplitudes` and `EfficientSU2`) as instructed, print their structures, and provide a rationale for exploring them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abaaff73"
      },
      "outputs": [],
      "source": [
        "# 1. Import necessary modules from Qiskit\n",
        "# Imports for QuantumCircuit, ZZFeatureMap, RealAmplitudes are already done in previous cells.\n",
        "# Import EfficientSU2\n",
        "from qiskit.circuit.library import EfficientSU2\n",
        "\n",
        "# Assuming num_qubits is still 3 based on previous PCA step for now,\n",
        "# although the feature selection step selected 50 features.\n",
        "# For VQC demonstration purposes with current simulator limits, we'll continue with 3 qubits.\n",
        "# NOTE: To use 50 features with VQC, significantly more qubits and potentially different\n",
        "# quantum hardware or advanced techniques would be required.\n",
        "\n",
        "# Let's redefine num_qubits based on the original PCA selection for this VQC part\n",
        "num_qubits = 3 # Revert to 3 qubits as used in the VQC setup previously\n",
        "\n",
        "# 2. Define an alternative feature map (e.g., EfficientSU2)\n",
        "# EfficientSU2 can also be used as a feature map, varying input data\n",
        "alt_feature_map = EfficientSU2(num_qubits, reps=1, entanglement='linear')\n",
        "alt_feature_map.user_parameters = alt_feature_map.parameters # Needed for QNN compatibility\n",
        "\n",
        "# 3. Define an alternative ansatz circuit (e.g., a deeper RealAmplitudes or EfficientSU2)\n",
        "# Deeper RealAmplitudes with more repetitions\n",
        "alt_ansatz_deeper = RealAmplitudes(num_qubits, reps=3, entanglement='linear')\n",
        "\n",
        "# EfficientSU2 used as an ansatz\n",
        "alt_ansatz_efficient = EfficientSU2(num_qubits, reps=1, entanglement='linear')\n",
        "\n",
        "\n",
        "# 4. Print or display the structure of the defined alternative circuits\n",
        "print(\"Alternative Feature Map (EfficientSU2) Structure:\")\n",
        "print(alt_feature_map.draw())\n",
        "\n",
        "print(\"\\nAlternative Ansatz (Deeper RealAmplitudes) Structure:\")\n",
        "print(alt_ansatz_deeper.draw())\n",
        "\n",
        "print(\"\\nAlternative Ansatz (EfficientSU2) Structure:\")\n",
        "print(alt_ansatz_efficient.draw())\n",
        "\n",
        "\n",
        "# 5. Briefly explain the rationale\n",
        "print(\"\\nRationale for Alternative Circuits:\")\n",
        "print(\"- **Alternative Feature Map (EfficientSU2):** EfficientSU2 is a hardware-efficient ansatz that can also serve as a feature map. Its structure with SU(2) single-qubit rotations and CNOT entanglers can potentially encode classical data into quantum states in a different way than ZZFeatureMap, possibly capturing different data correlations.\")\n",
        "print(\"- **Alternative Ansatz (Deeper RealAmplitudes):** Increasing the number of repetitions (layers) in the RealAmplitudes ansatz provides more trainable parameters. This increased depth can allow the VQC to learn more complex functions and potentially improve its ability to classify non-linearly separable data.\")\n",
        "print(\"- **Alternative Ansatz (EfficientSU2):** Using EfficientSU2 as an ansatz offers a different parameterized structure compared to RealAmplitudes. Its specific arrangement of rotations and entanglers might be better suited for certain types of data landscapes or be more robust to noise on real hardware (due to being hardware-efficient).\")\n",
        "print(\"\\nThese alternatives will be explored in subsequent steps to see if they can improve the VQC's performance compared to the initial setup.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "989d0d85"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "# Define the filename for the saved model\n",
        "model_filename = 'vqc_classifier_model.joblib'\n",
        "\n",
        "# Save the trained VQC classifier to the file\n",
        "try:\n",
        "    joblib.dump(vqc_classifier, model_filename)\n",
        "    print(f\"VQC model successfully saved to '{model_filename}'\")\n",
        "\n",
        "    # Provide a link to download the file in Colab\n",
        "    from google.colab import files\n",
        "    files.download(model_filename)\n",
        "\n",
        "except NameError:\n",
        "    print(\"Error: vqc_classifier is not defined. Please ensure the VQC training cell was run successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the model: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N14iE79OO4Gi"
      },
      "outputs": [],
      "source": [
        "import joblib, pickle\n",
        "\n",
        "joblib.dump(classical_model, \"/content/drive/MyDrive/classical_fraud_model.pkl\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/vqc_fraud_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vqc_classifier, f)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}